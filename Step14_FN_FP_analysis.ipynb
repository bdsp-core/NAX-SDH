{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load in the False Positives\n",
    "\n",
    "df_fp=pd.read_csv(\"/home/gregory178/Desktop/NAX project/NAX_SDH/false_positive_ids.csv\")\n",
    "\n",
    "#Load in the False Negatives\n",
    "df_fn=pd.read_csv(\"/home/gregory178/Desktop/NAX project/NAX_SDH/false_negative_ids.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated filtered rows with note content saved to /home/gregory178/Desktop/NAX project/NAX_SDH/false_positives_with_notes.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Read filtered_rows.csv\n",
    "# Assume df_fp is already defined; if not, you would need to load it here.\n",
    "filtered_rows = df_fp  # This should be replaced with actual code if df_fp is not defined\n",
    "\n",
    "# Step 2: Define file paths for MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv\n",
    "file2_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/MGB_Complete_Notes.csv'\n",
    "file3_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/BIDMC_Complete_Notes.csv'\n",
    "\n",
    "# Step 3: Read MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv\n",
    "file2 = pd.read_csv(file2_path)\n",
    "file3 = pd.read_csv(file3_path)\n",
    "\n",
    "# Step 4: Merge note content based on BDSPPatientID\n",
    "merged_file2 = filtered_rows.merge(file2[['BDSPPatientID', 'NoteContent']], how='left', on='BDSPPatientID', suffixes=('', '_MGB'))\n",
    "merged_file3 = filtered_rows.merge(file3[['BDSPPatientID', 'NoteContent']], how='left', on='BDSPPatientID', suffixes=('', '_BIDMC'))\n",
    "\n",
    "# Step 5: Combine note content from both files into a single column NoteContent\n",
    "# Use fillna to prioritize content from the first file if present, otherwise use content from the second file\n",
    "filtered_rows['NoteContent'] = merged_file2['NoteContent'].fillna(merged_file3['NoteContent'])\n",
    "\n",
    "# Step 6: Save updated filtered_rows with NoteContent to a new CSV\n",
    "output_with_notes_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/false_positives_with_notes.csv'\n",
    "filtered_rows.to_csv(output_with_notes_path, index=False)\n",
    "\n",
    "print(f\"Updated filtered rows with note content saved to {output_with_notes_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated filtered rows with note content saved to /home/gregory178/Desktop/NAX project/NAX_SDH/false_negatives_with_notes.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Read filtered_rows_neg.csv\n",
    "filtered_rows_neg = df_fn\n",
    "# Step 2: Define file paths for MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv\n",
    "file2_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/MGB_Complete_Notes.csv'\n",
    "file3_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/BIDMC_Complete_Notes.csv'\n",
    "\n",
    "# Step 3: Read MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv\n",
    "file2 = pd.read_csv(file2_path)\n",
    "file3 = pd.read_csv(file3_path)\n",
    "\n",
    "# Step 4: Merge note content based on BDSPPatientID\n",
    "merged_file2 = filtered_rows_neg.merge(file2, how='left', left_on='BDSPPatientID', right_on='BDSPPatientID')\n",
    "merged_file3 = filtered_rows_neg.merge(file3, how='left', left_on='BDSPPatientID', right_on='BDSPPatientID')\n",
    "\n",
    "# Step 4: Merge note content based on BDSPPatientID\n",
    "# merged_file2 = filtered_rows_neg.merge(file2, how='left', left_on='Unnamed: 0', right_on='BDSPPatientID')\n",
    "# merged_file3 = filtered_rows_neg.merge(file3, how='left', left_on='Unnamed: 0', right_on='BDSPPatientID')\n",
    "\n",
    "# Step 5: Combine note content from both files into a single column NoteContent\n",
    "filtered_rows_neg['NoteContent'] = merged_file2['NoteContent'].fillna(merged_file3['NoteContent'])\n",
    "\n",
    "\n",
    "# Step 6: Save updated filtered_rows_neg with NoteContent to a new CSV\n",
    "output_with_notes_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/false_negatives_with_notes.csv'\n",
    "filtered_rows_neg.to_csv(output_with_notes_path, index=False)\n",
    "\n",
    "print(f\"Updated filtered rows with note content saved to {output_with_notes_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1: Read filtered_rows_error.csv\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Assume df_fp is already defined; if not, you would need to load it here.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m filtered_rows_error \u001b[38;5;241m=\u001b[39m df_error  \u001b[38;5;66;03m# This should be replaced with actual code if df_fp is not defined\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Step 2: Define file paths for MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv\u001b[39;00m\n\u001b[1;32m      6\u001b[0m file2_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/gregory178/Desktop/NAX project/NAX_SDH/MGB_Complete_Notes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_error' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Read filtered_rows_error.csv\n",
    "# Assume df_fp is already defined; if not, you would need to load it here.\n",
    "filtered_rows_error = df_error  # This should be replaced with actual code if df_fp is not defined\n",
    "\n",
    "# Step 2: Define file paths for MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv\n",
    "file2_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/MGB_Complete_Notes.csv'\n",
    "file3_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/BIDMC_Complete_Notes.csv'\n",
    "\n",
    "# Step 3: Read MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv\n",
    "file2 = pd.read_csv(file2_path)\n",
    "file3 = pd.read_csv(file3_path)\n",
    "\n",
    "# Step 4: Merge note content based on BDSPPatientID\n",
    "merged_file2 = filtered_rows_error.merge(file2[['BDSPPatientID', 'NoteContent']], how='left', on='BDSPPatientID', suffixes=('', '_MGB'))\n",
    "merged_file3 = filtered_rows_error.merge(file3[['BDSPPatientID', 'NoteContent']], how='left', on='BDSPPatientID', suffixes=('', '_BIDMC'))\n",
    "\n",
    "# Step 5: Combine note content from both files into a single column NoteContent\n",
    "# Use fillna to prioritize content from the first file if present, otherwise use content from the second file\n",
    "filtered_rows_error['NoteContent'] = merged_file2['NoteContent'].fillna(merged_file3['NoteContent'])\n",
    "\n",
    "# Step 6: Save updated filtered_rows_error with NoteContent to a new CSV\n",
    "output_with_notes_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/demographic_error_MGB_with_notes.csv'\n",
    "filtered_rows_error.to_csv(output_with_notes_path, index=False)\n",
    "\n",
    "print(f\"Updated filtered rows with note content saved to {output_with_notes_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDSPPatientIDs present in both CSV files:\n",
      "120373601\n",
      "113125826\n",
      "151236355\n",
      "122027271\n",
      "150008106\n",
      "151253164\n",
      "150003217\n",
      "151143222\n",
      "150009180\n",
      "116318814\n",
      "\n",
      "BDSPPatientIDs present in df2 but not in df1:\n"
     ]
    }
   ],
   "source": [
    "####This is code to see what BDSPPatientIDs are shared between two csvs:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files into DataFrames\n",
    "csv1_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/false_negative_ids.csv'\n",
    "csv2_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/false_negative_ids_best_model.csv'\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(csv1_path)\n",
    "df2 = pd.read_csv(csv2_path)\n",
    "\n",
    "# Ensure 'BDSPPatientID' column exists in both DataFrames\n",
    "if 'BDSPPatientID' not in df1.columns or 'BDSPPatientID' not in df2.columns:\n",
    "    raise ValueError(\"'BDSPPatientID' column is missing in one of the CSV files.\")\n",
    "\n",
    "# Get sets of 'BDSPPatientID' from both DataFrames\n",
    "ids_csv1 = set(df1['BDSPPatientID'])\n",
    "ids_csv2 = set(df2['BDSPPatientID'])\n",
    "\n",
    "# Find common 'BDSPPatientID's\n",
    "common_ids = ids_csv1.intersection(ids_csv2)\n",
    "\n",
    "# Find 'BDSPPatientID's in df2 that are not in df1\n",
    "unique_to_df2 = ids_csv2 - ids_csv1\n",
    "\n",
    "# Print out the common 'BDSPPatientID's\n",
    "print(\"BDSPPatientIDs present in both CSV files:\")\n",
    "for patient_id in common_ids:\n",
    "    print(patient_id)\n",
    "\n",
    "# Print out the 'BDSPPatientID's that are in df2 but not in df1\n",
    "print(\"\\nBDSPPatientIDs present in df2 but not in df1:\")\n",
    "for patient_id in unique_to_df2:\n",
    "    print(patient_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDSPPatientIDs present in both CSV files:\n",
      "150015490\n",
      "116510723\n",
      "150007686\n",
      "111793289\n",
      "150011917\n",
      "111626896\n",
      "150003985\n",
      "116121874\n",
      "121229724\n",
      "150024732\n",
      "112065953\n",
      "120714530\n",
      "151027748\n",
      "150688553\n",
      "150000687\n",
      "150649394\n",
      "118306612\n",
      "150008246\n",
      "150008503\n",
      "150805440\n",
      "114433472\n",
      "121117250\n",
      "112623695\n",
      "120934736\n",
      "150000337\n",
      "150005076\n",
      "119821653\n",
      "111355735\n",
      "119906019\n",
      "115294076\n",
      "115038825\n",
      "150055914\n",
      "115539691\n",
      "150867180\n",
      "122476267\n",
      "120448878\n",
      "121233135\n",
      "116269678\n",
      "114993651\n",
      "114644220\n",
      "\n",
      "BDSPPatientIDs present in df2 but not in df1:\n",
      "150016332\n",
      "151036497\n",
      "151077782\n",
      "115682334\n",
      "150208412\n",
      "151286906\n",
      "116783621\n",
      "116064158\n",
      "121786134\n",
      "118095895\n",
      "112993800\n",
      "150654988\n",
      "150987094\n",
      "150011047\n",
      "150015988\n",
      "113605123\n",
      "118650222\n",
      "116508906\n",
      "150002456\n",
      "150004872\n",
      "115082737\n",
      "151224710\n",
      "151079959\n",
      "151339276\n",
      "151050548\n",
      "111604561\n",
      "119529975\n",
      "150004868\n",
      "116617545\n",
      "117223285\n",
      "122055289\n",
      "118054160\n",
      "150008624\n",
      "\n",
      "Number of BDSPPatientIDs present in both CSV files: 40\n",
      "Number of BDSPPatientIDs present in df2 after removing common IDs: 33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the CSV files into DataFrames\n",
    "csv1_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/false_positive_ids.csv'\n",
    "csv2_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/false_positive_ids_best_model.csv'\n",
    "\n",
    "df1 = pd.read_csv(csv1_path)\n",
    "df2 = pd.read_csv(csv2_path)\n",
    "\n",
    "# Ensure 'BDSPPatientID' column exists in both DataFrames\n",
    "if 'BDSPPatientID' not in df1.columns or 'BDSPPatientID' not in df2.columns:\n",
    "    raise ValueError(\"'BDSPPatientID' column is missing in one of the CSV files.\")\n",
    "\n",
    "# Get sets of 'BDSPPatientID' from both DataFrames\n",
    "ids_csv1 = set(df1['BDSPPatientID'])\n",
    "ids_csv2 = set(df2['BDSPPatientID'])\n",
    "\n",
    "# Find common 'BDSPPatientID's\n",
    "common_ids = ids_csv1.intersection(ids_csv2)\n",
    "\n",
    "# Drop rows in df2 where 'BDSPPatientID' is in common_ids\n",
    "df2_unique = df2[~df2['BDSPPatientID'].isin(common_ids)]\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "df2_unique.to_csv('/home/gregory178/Desktop/NAX project/NAX_SDH/false_positive_unique.csv', index=False)\n",
    "\n",
    "# Count the number of common and unique 'BDSPPatientID's\n",
    "num_common = len(common_ids)\n",
    "num_unique_to_df2 = len(df2_unique)\n",
    "\n",
    "# Print out the common 'BDSPPatientID's\n",
    "print(\"BDSPPatientIDs present in both CSV files:\")\n",
    "for patient_id in common_ids:\n",
    "    print(patient_id)\n",
    "\n",
    "# Print out the 'BDSPPatientID's that are in df2 but not in df1\n",
    "print(\"\\nBDSPPatientIDs present in df2 but not in df1:\")\n",
    "for patient_id in df2_unique['BDSPPatientID']:\n",
    "    print(patient_id)\n",
    "\n",
    "# Print counts of common and unique 'BDSPPatientID's\n",
    "print(f\"\\nNumber of BDSPPatientIDs present in both CSV files: {num_common}\")\n",
    "print(f\"Number of BDSPPatientIDs present in df2 after removing common IDs: {num_unique_to_df2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Step 1: Read filtered_rows.csv\n",
    "# filtered_rows_path = '/home/gregory178/Desktop/NAX project/NAX_SDHDraft_5/filtered_rows.csv'\n",
    "# filtered_rows = pd.read_csv(filtered_rows_path)\n",
    "\n",
    "# # Step 2: Define file paths for MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv\n",
    "# file2_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/MGB_Complete_Notes.csv'\n",
    "# file3_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/BIDMC_Complete_Notes.csv'\n",
    "\n",
    "# # Step 3: Read MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv\n",
    "# file2 = pd.read_csv(file2_path)\n",
    "# file3 = pd.read_csv(file3_path)\n",
    "\n",
    "# # Step 4: Merge note content based on BDSPPatientID\n",
    "# merged_file2 = filtered_rows.merge(file2, how='left', left_on='Unnamed: 0', right_on='BDSPPatientID')\n",
    "# merged_file3 = filtered_rows.merge(file3, how='left', left_on='Unnamed: 0', right_on='BDSPPatientID')\n",
    "\n",
    "# # Step 5: Combine note content from both files into a single column NoteContent\n",
    "# filtered_rows['NoteContent'] = merged_file2['NoteContent'].fillna(merged_file3['NoteContent'])\n",
    "\n",
    "# # Step 6: Validate matches between Unnamed: 0/NoteContent and BDSPPatientID/NoteContent\n",
    "# for index, row in filtered_rows.iterrows():\n",
    "#     if pd.notna(row['BDSPPatientID']):\n",
    "#         if row['Unnamed: 0'] == row['BDSPPatientID'] and row['NoteContent_x'] == row['NoteContent_y']:\n",
    "#             print(f\"Row {index}: Matches\")\n",
    "#         else:\n",
    "#             print(f\"Row {index}: Doesn't match\")\n",
    "\n",
    "# # # Step 7: Save updated filtered_rows with NoteContent to a new CSV\n",
    "# # output_with_notes_path = '/home/gregory178/Desktop/NAX project/NAX_SDHDraft_5/filtered_rows_with_notes.csv'\n",
    "# # filtered_rows.to_csv(output_with_notes_path, index=False)\n",
    "\n",
    "# # print(f\"Updated filtered rows with note content saved to {output_with_notes_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
