{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 14 allows for the annotator to review the csvs for false_positive and false_negative cases from Random Forest testing on both hospitals. \n",
    "#Follow the instructions in the annotation tool folder for creating a username and password and input the file path from this step into the READ_ME.py. \n",
    "#Afterwards go to the annotation folder outside of the code and click the annotation tool and analyze the lists of false positives and false negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary module. \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the False Positives.\n",
    "df_fp=pd.read_csv(\"/home/gregory178/Desktop/NAX project/NAX_SDH/false_positive_ids.csv\")\n",
    "\n",
    "#Load in the False Negatives.\n",
    "df_fn=pd.read_csv(\"/home/gregory178/Desktop/NAX project/NAX_SDH/false_negative_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated filtered rows with note content saved to /home/gregory178/Desktop/NAX project/NAX_SDH/false_positives_with_notes.csv\n"
     ]
    }
   ],
   "source": [
    "#Retrieve the notes for the patients with false positive patient ids. \n",
    "\n",
    "#Step 1: Read filtered_rows.csv.\n",
    "filtered_rows = df_fp  \n",
    "\n",
    "#Step 2: Define file paths for MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv.\n",
    "file2_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/MGB_Complete_Notes.csv'\n",
    "file3_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/BIDMC_Complete_Notes.csv'\n",
    "\n",
    "#Step 3: Read MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv.\n",
    "file2 = pd.read_csv(file2_path)\n",
    "file3 = pd.read_csv(file3_path)\n",
    "\n",
    "#Step 4: Merge note content based on BDSPPatientID.\n",
    "merged_file2 = filtered_rows.merge(file2[['BDSPPatientID', 'NoteContent']], how='left', on='BDSPPatientID', suffixes=('', '_MGB'))\n",
    "merged_file3 = filtered_rows.merge(file3[['BDSPPatientID', 'NoteContent']], how='left', on='BDSPPatientID', suffixes=('', '_BIDMC'))\n",
    "\n",
    "#Step 5: Combine note content from both files into a single column NoteContent.\n",
    "filtered_rows['NoteContent'] = merged_file2['NoteContent'].fillna(merged_file3['NoteContent'])\n",
    "\n",
    "#Step 6: Save updated filtered_rows with NoteContent to a new CSV.\n",
    "output_with_notes_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/false_positives_with_notes.csv'\n",
    "filtered_rows.to_csv(output_with_notes_path, index=False)\n",
    "print(f\"Updated filtered rows with note content saved to {output_with_notes_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated filtered rows with note content saved to /home/gregory178/Desktop/NAX project/NAX_SDH/false_negatives_with_notes.csv\n"
     ]
    }
   ],
   "source": [
    "#Retrieve the notes for the patients with false negative patient ids. \n",
    "\n",
    "#Step 1: Read filtered_rows_neg.csv.\n",
    "filtered_rows_neg = df_fn\n",
    "\n",
    "#Step 2: Define file paths for MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv.\n",
    "file2_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/MGB_Complete_Notes.csv'\n",
    "file3_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/BIDMC_Complete_Notes.csv'\n",
    "\n",
    "#Step 3: Read MGB_Complete_Notes.csv and BIDMC_Complete_Notes.csv.\n",
    "file2 = pd.read_csv(file2_path)\n",
    "file3 = pd.read_csv(file3_path)\n",
    "\n",
    "#Step 4: Merge note content based on BDSPPatientID.\n",
    "merged_file2 = filtered_rows_neg.merge(file2, how='left', left_on='BDSPPatientID', right_on='BDSPPatientID')\n",
    "merged_file3 = filtered_rows_neg.merge(file3, how='left', left_on='BDSPPatientID', right_on='BDSPPatientID')\n",
    "\n",
    "#Step 5: Combine note content from both files into a single column NoteContent.\n",
    "filtered_rows_neg['NoteContent'] = merged_file2['NoteContent'].fillna(merged_file3['NoteContent'])\n",
    "\n",
    "\n",
    "#Step 6: Save updated filtered_rows_neg with NoteContent to a new CSV.\n",
    "output_with_notes_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/false_negatives_with_notes.csv'\n",
    "filtered_rows_neg.to_csv(output_with_notes_path, index=False)\n",
    "print(f\"Updated filtered rows with note content saved to {output_with_notes_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDSPPatientIDs present in both CSV files:\n",
      "120373601\n",
      "113125826\n",
      "151236355\n",
      "122027271\n",
      "150008106\n",
      "151253164\n",
      "150003217\n",
      "151143222\n",
      "150009180\n",
      "116318814\n",
      "\n",
      "BDSPPatientIDs present in df2 but not in df1:\n"
     ]
    }
   ],
   "source": [
    "#This code verifies that the following dataframes share the same ids. \n",
    "\n",
    "#Load the CSV files into DataFrames\n",
    "csv1_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/false_negative_ids.csv'\n",
    "csv2_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/false_negative_ids_best_model.csv'\n",
    "\n",
    "df1 = pd.read_csv(csv1_path)\n",
    "df2 = pd.read_csv(csv2_path)\n",
    "\n",
    "#Ensure 'BDSPPatientID' column exists in both DataFrames.\n",
    "if 'BDSPPatientID' not in df1.columns or 'BDSPPatientID' not in df2.columns:\n",
    "    raise ValueError(\"'BDSPPatientID' column is missing in one of the CSV files.\")\n",
    "\n",
    "#Get sets of 'BDSPPatientID' from both DataFrames.\n",
    "ids_csv1 = set(df1['BDSPPatientID'])\n",
    "ids_csv2 = set(df2['BDSPPatientID'])\n",
    "\n",
    "#Find common 'BDSPPatientID's.\n",
    "common_ids = ids_csv1.intersection(ids_csv2)\n",
    "\n",
    "#Find 'BDSPPatientID's in df2 that are not in df1.\n",
    "unique_to_df2 = ids_csv2 - ids_csv1\n",
    "\n",
    "#Print out the common 'BDSPPatientID's.\n",
    "print(\"BDSPPatientIDs present in both CSV files:\")\n",
    "for patient_id in common_ids:\n",
    "    print(patient_id)\n",
    "\n",
    "#Print out the 'BDSPPatientID's that are in df2 but not in df1.\n",
    "print(\"\\nBDSPPatientIDs present in df2 but not in df1:\")\n",
    "for patient_id in unique_to_df2:\n",
    "    print(patient_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDSPPatientIDs present in both CSV files:\n",
      "150015490\n",
      "116510723\n",
      "150007686\n",
      "111793289\n",
      "150011917\n",
      "111626896\n",
      "150003985\n",
      "116121874\n",
      "121229724\n",
      "150024732\n",
      "112065953\n",
      "120714530\n",
      "151027748\n",
      "150688553\n",
      "150000687\n",
      "150649394\n",
      "118306612\n",
      "150008246\n",
      "150008503\n",
      "150805440\n",
      "114433472\n",
      "121117250\n",
      "112623695\n",
      "120934736\n",
      "150000337\n",
      "150005076\n",
      "119821653\n",
      "111355735\n",
      "119906019\n",
      "115294076\n",
      "115038825\n",
      "150055914\n",
      "115539691\n",
      "150867180\n",
      "122476267\n",
      "120448878\n",
      "121233135\n",
      "116269678\n",
      "114993651\n",
      "114644220\n",
      "\n",
      "BDSPPatientIDs present in df2 but not in df1:\n",
      "150016332\n",
      "151036497\n",
      "151077782\n",
      "115682334\n",
      "150208412\n",
      "151286906\n",
      "116783621\n",
      "116064158\n",
      "121786134\n",
      "118095895\n",
      "112993800\n",
      "150654988\n",
      "150987094\n",
      "150011047\n",
      "150015988\n",
      "113605123\n",
      "118650222\n",
      "116508906\n",
      "150002456\n",
      "150004872\n",
      "115082737\n",
      "151224710\n",
      "151079959\n",
      "151339276\n",
      "151050548\n",
      "111604561\n",
      "119529975\n",
      "150004868\n",
      "116617545\n",
      "117223285\n",
      "122055289\n",
      "118054160\n",
      "150008624\n",
      "\n",
      "Number of BDSPPatientIDs present in both CSV files: 40\n",
      "Number of BDSPPatientIDs present in df2 after removing common IDs: 33\n"
     ]
    }
   ],
   "source": [
    "#This code verifies that the following dataframes share the same ids. \n",
    "\n",
    "#Load the CSV files into DataFrames\n",
    "csv1_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/false_positive_ids.csv'\n",
    "csv2_path = '/home/gregory178/Desktop/NAX project/NAX_SDH/false_positive_ids_best_model.csv'\n",
    "\n",
    "df1 = pd.read_csv(csv1_path)\n",
    "df2 = pd.read_csv(csv2_path)\n",
    "\n",
    "#Ensure 'BDSPPatientID' column exists in both DataFrames.\n",
    "if 'BDSPPatientID' not in df1.columns or 'BDSPPatientID' not in df2.columns:\n",
    "    raise ValueError(\"'BDSPPatientID' column is missing in one of the CSV files.\")\n",
    "\n",
    "#Get sets of 'BDSPPatientID' from both DataFrames.\n",
    "ids_csv1 = set(df1['BDSPPatientID'])\n",
    "ids_csv2 = set(df2['BDSPPatientID'])\n",
    "\n",
    "#Find common 'BDSPPatientID's.\n",
    "common_ids = ids_csv1.intersection(ids_csv2)\n",
    "\n",
    "#Drop rows in df2 where 'BDSPPatientID' is in common_ids.\n",
    "df2_unique = df2[~df2['BDSPPatientID'].isin(common_ids)]\n",
    "\n",
    "#Save the result to a new CSV file.\n",
    "df2_unique.to_csv('/home/gregory178/Desktop/NAX project/NAX_SDH/false_positive_unique.csv', index=False)\n",
    "\n",
    "#Count the number of common and unique 'BDSPPatientID's.\n",
    "num_common = len(common_ids)\n",
    "num_unique_to_df2 = len(df2_unique)\n",
    "\n",
    "#Print out the common 'BDSPPatientID's.\n",
    "print(\"BDSPPatientIDs present in both CSV files:\")\n",
    "for patient_id in common_ids:\n",
    "    print(patient_id)\n",
    "\n",
    "#Print out the 'BDSPPatientID's that are in df2 but not in df1.\n",
    "print(\"\\nBDSPPatientIDs present in df2 but not in df1:\")\n",
    "for patient_id in df2_unique['BDSPPatientID']:\n",
    "    print(patient_id)\n",
    "\n",
    "#Print counts of common and unique 'BDSPPatientID's.\n",
    "print(f\"\\nNumber of BDSPPatientIDs present in both CSV files: {num_common}\")\n",
    "print(f\"Number of BDSPPatientIDs present in df2 after removing common IDs: {num_unique_to_df2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
