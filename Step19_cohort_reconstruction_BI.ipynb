{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Installing necessary modules to run the code. Make sure to install thunderpack if not yet installed: pip install thunderpack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from thunderpack import ThunderReader  \n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##We are now going to pull the BDSPPatientID, Admission date, and DiagnosisCodeWithDots for each patient.\n",
    "##We then need to randomly select 10,000 of them\n",
    "###Then we need to iterate for ICD code and make sure that the ICD code is within a cetain time period of them being seen. \n",
    "#Then we need to pull out the number of patients who have a positive ICD code. \n",
    "#Then we need to estimate the overall error rate\n",
    "\n",
    "#Start with BIDMC first\n",
    "\n",
    "df=pd.read_csv(\"/home/gregory178/Desktop/NAX project/NAX_dive/complete_df_initial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = df.sample(frac=1, random_state=2024, ignore_index=True)  # shuffling\n",
    "unique = random.drop_duplicates(subset='BDSPPatientID', keep='first', ignore_index=True)\n",
    "random_unique = unique.sample(n=10000, random_state=2024, ignore_index=True)\n",
    "ids = list(random_unique['BDSPPatientID'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:37<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "reader = ThunderReader('/media/gregory178/Thunderpacks/Dropbox/zz_EHR_Thunderpacks/BIDMC/thunderpack_icd_9_10_nax_1m_BIDMC')\n",
    "key_length = len(list(reader.keys()))\n",
    "dfs = []\n",
    "for i in tqdm(range(1, key_length + 1)):\n",
    "    df = reader[f'ICD_partition_{i}']\n",
    "    df = df[df['BDSPPatientID'].isin(ids)]\n",
    "    df = df.drop(columns=['BDSPEncounterID', 'DiagnosisSequenceNumber', 'DiagnosisPoaInd', \n",
    "                                        'ShortDescription', 'LongDescription', 'DiagnosisType', \n",
    "                                        'BDSPLastModifiedDTS', 'code_type', 'DischargeDate'])\n",
    "    df['AdmissionDate'] = pd.to_datetime(df['AdmissionDate'])\n",
    "    dfs.append(df)\n",
    "icd_df = pd.concat(dfs, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BDSPPatientID</th>\n",
       "      <th>DiagnosisCode</th>\n",
       "      <th>DiagnosisCodeWithDots</th>\n",
       "      <th>AdmissionDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150071046</td>\n",
       "      <td>41401</td>\n",
       "      <td>414.01</td>\n",
       "      <td>2011-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150071046</td>\n",
       "      <td>42983</td>\n",
       "      <td>429.83</td>\n",
       "      <td>2011-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150071046</td>\n",
       "      <td>5990</td>\n",
       "      <td>599.0</td>\n",
       "      <td>2011-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150071046</td>\n",
       "      <td>25000</td>\n",
       "      <td>250.00</td>\n",
       "      <td>2011-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150071046</td>\n",
       "      <td>2724</td>\n",
       "      <td>272.4</td>\n",
       "      <td>2011-06-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BDSPPatientID DiagnosisCode DiagnosisCodeWithDots AdmissionDate\n",
       "0      150071046       41401                  414.01    2011-06-15\n",
       "1      150071046       42983                  429.83    2011-06-15\n",
       "2      150071046       5990                   599.0     2011-06-15\n",
       "3      150071046       25000                  250.00    2011-06-15\n",
       "4      150071046       2724                   272.4     2011-06-15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BDSPPatientID</th>\n",
       "      <th>NoteTypeFull</th>\n",
       "      <th>Service</th>\n",
       "      <th>CreateDate</th>\n",
       "      <th>DeidentifiedName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151310180</td>\n",
       "      <td>Initial note</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>Notes_1131168764_3416348191_20230526.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151188065</td>\n",
       "      <td>Initial note</td>\n",
       "      <td>Pain Management</td>\n",
       "      <td>2014-04-21</td>\n",
       "      <td>Notes_1131046805_426282968_20140421.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150020366</td>\n",
       "      <td>Initial note</td>\n",
       "      <td>Patient Financial Serives</td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>Notes_1129879243_3732266378_20230524.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150622094</td>\n",
       "      <td>Initial note</td>\n",
       "      <td>Nephrology</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>Notes_1130480893_1099015134_20200215.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150954407</td>\n",
       "      <td>Initial note</td>\n",
       "      <td>Gastroenterology</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>Notes_1130813198_2132813469_20160801.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BDSPPatientID  NoteTypeFull                    Service  CreateDate  \\\n",
       "0      151310180  Initial note                 Cardiology  2023-05-26   \n",
       "1      151188065  Initial note            Pain Management  2014-04-21   \n",
       "2      150020366  Initial note  Patient Financial Serives  2023-05-24   \n",
       "3      150622094  Initial note                 Nephrology  2020-02-15   \n",
       "4      150954407  Initial note           Gastroenterology  2016-08-01   \n",
       "\n",
       "                           DeidentifiedName  \n",
       "0  Notes_1131168764_3416348191_20230526.txt  \n",
       "1   Notes_1131046805_426282968_20140421.txt  \n",
       "2  Notes_1129879243_3732266378_20230524.txt  \n",
       "3  Notes_1130480893_1099015134_20200215.txt  \n",
       "4  Notes_1130813198_2132813469_20160801.txt  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Updated pattern\n",
    "pattern = re.compile(r'^(?:I62.0|S06.5|432.1|852.2|852.3)')\n",
    "\n",
    "def check_icd_in_period(id_, date):\n",
    "    # Convert date to pandas Timestamp if it's not already\n",
    "    if isinstance(date, str):\n",
    "        date = pd.to_datetime(date)\n",
    "        \n",
    "    # Define the date range (one month leading up to note)\n",
    "    start_date = date - pd.DateOffset(days=30)\n",
    "    end_date = date + pd.DateOffset(days=30)\n",
    "    \n",
    "    # Ensure AdmissionDate is a pandas Timestamp\n",
    "    if not pd.api.types.is_datetime64_any_dtype(icd_df['AdmissionDate']):\n",
    "        icd_df['AdmissionDate'] = pd.to_datetime(icd_df['AdmissionDate'])\n",
    "    \n",
    "    # Filter icd_df for matching ID and date range\n",
    "    mask = (icd_df['BDSPPatientID'] == id_) & (icd_df['AdmissionDate'] > start_date) & (icd_df['AdmissionDate'] < end_date)\n",
    "    filtered_df = icd_df.loc[mask]\n",
    "    \n",
    "    # Check for regex pattern match in 'DiagnosisCodeWithDots' column\n",
    "    if filtered_df['DiagnosisCodeWithDots'].str.contains(pattern).any():\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Apply the function to each row of random_unique\n",
    "random_unique['ICD'] = random_unique.apply(lambda row: check_icd_in_period(row['BDSPPatientID'], row['CreateDate']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total random patients: 10000\n",
      "Total +ICD: 92\n",
      "Total -ICD: 9908\n",
      "Prevalence: 0.0092\n"
     ]
    }
   ],
   "source": [
    "print(f'Total random patients: {len(random_unique)}')\n",
    "print(f'Total +ICD: {sum(random_unique[\"ICD\"])}')\n",
    "print(f'Total -ICD: {len(random_unique[random_unique[\"ICD\"] == 0])}')\n",
    "print(f'Prevalence: {sum(random_unique[\"ICD\"]) / len(random_unique)}')\n",
    "\n",
    "prev_ICD_p = sum(random_unique[\"ICD\"]) / len(random_unique)\n",
    "prev_ICD_n = sum(1-random_unique[\"ICD\"]) / len(random_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_unique.to_csv('BI_random_unique.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get group variable for the testing feature matrix, so that we can get error rate (1-accuracy) in each group\n",
    "#Not really sure what to do here. \n",
    "\n",
    "# load the testing feature matrix\n",
    "df_test = pd.read_csv('/home/gregory178/Desktop/NAX project/NAX_SDH/Complete_merged_feature_matrix_notes_CPT_and_ICD_.csv')\n",
    "\n",
    "# load the model prediction for the testing feature matrix\n",
    "df_pred = pd.read_csv('BI_y_and_y_pred.csv') ### Hi Greg, do you know where is file is? We generated it in (maybe) step14, but it's not there anymore. -- Haoqi\n",
    "df_pred = df_test.merge(df_pred, on='BDSPPatientID', how='inner', validate='1:1')\n",
    "\n",
    "# get the group\n",
    "\n",
    "# this is an old method to get ICD+/ICD- group, based on searching ICD codes\n",
    "#df_test['Group'] = df_test.apply(lambda row: check_icd_in_period(row['BDSPPatientID'], row['ContactDate']), axis=1)\n",
    "\n",
    "# however, there was some problem with this method\n",
    "# so we decided to use a list of patient IDs (BDSPPatientID) during sampling cohort construction\n",
    "df_icd_p = pd.read_csv('/home/gregory178/Desktop/NAX project/NAX_SDH/bidmc_pos_icd.csv')\n",
    "\n",
    "df_pred['Group'] = np.in1d(df_pred.BDSPPatientID, df_icd_p.BDSPPatientID).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "print((df_pred.Group==1).sum())\n",
    "print((df_pred.Group==0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('BI_df_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003557333333333334\n"
     ]
    }
   ],
   "source": [
    "# get error rate per group\n",
    "\n",
    "### removed old code\n",
    "#y_pred = df_pred.y_pred\n",
    "#error_rater_ICD_p = 1 - np.mean( df_test.annotation[df_test.Group==1] == y_pred[df_test.Group==1] )\n",
    "#error_rater_ICD_n = 1 - np.mean( df_test.annotation[df_test.Group==0] == y_pred[df_test.Group==0] )\n",
    "### this is the new code\n",
    "error_rater_ICD_p = 1 - np.mean( df_pred.y[df_pred.Group==1] == df_pred.y_pred[df_pred.Group==1] )\n",
    "error_rater_ICD_n = 1 - np.mean( df_pred.y[df_pred.Group==0] == df_pred.y_pred[df_pred.Group==0] )\n",
    "\n",
    "# get the final error rate!!\n",
    "final_error_rate = error_rater_ICD_p*prev_ICD_p + error_rater_ICD_n*prev_ICD_n\n",
    "\n",
    "print(final_error_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Need to put this somewhere in other code: \n",
    "# save model prediction\n",
    "\n",
    "df_pred = pd.DataFrame(data={\n",
    "    'BDSPPatientID':matrix.BDSPPatientID,\n",
    "    'y':y_holdout,\n",
    "    'y_pred':y_pred,\n",
    "    'y_pred_proba':y_pred_proba,\n",
    "})\n",
    "print(df_pred)\n",
    "df_pred.to_csv('test_both_hospitals_y_and_y_pred.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Sample 10,000 random rows with a specific random state for reproducibility\n",
    "# sampled_df = complete_df_initial.sample(n=10000, random_state=101)\n",
    "\n",
    "# # Find duplicated BDSPPatientID rows\n",
    "# duplicates_df = sampled_df[sampled_df.duplicated(subset='BDSPPatientID', keep=False)]\n",
    "\n",
    "# # Identify all duplicate IDs\n",
    "# duplicate_ids = duplicates_df['BDSPPatientID'].unique()\n",
    "\n",
    "# # Randomly select which duplicates to keep\n",
    "# def keep_random_duplicates(df, duplicate_ids):\n",
    "#     # For each duplicate ID, randomly select one occurrence to keep\n",
    "#     df_unique = pd.DataFrame()\n",
    "#     for patient_id in duplicate_ids:\n",
    "#         df_id = df[df['BDSPPatientID'] == patient_id]\n",
    "#         df_unique = pd.concat([df_unique, df_id.sample(n=1, random_state=102)])  # Randomly keep one instance\n",
    "    \n",
    "#     return df_unique\n",
    "\n",
    "# # Get one instance of each duplicate BDSPPatientID\n",
    "# unique_duplicates_df = keep_random_duplicates(sampled_df, duplicate_ids)\n",
    "\n",
    "# # Filter out the duplicates from the sampled_df\n",
    "# non_duplicate_df = sampled_df[~sampled_df['BDSPPatientID'].isin(duplicate_ids)]\n",
    "\n",
    "# # Combine the kept duplicates with non-duplicates\n",
    "# cleaned_sampled_df = pd.concat([non_duplicate_df, unique_duplicates_df], ignore_index=True)\n",
    "\n",
    "# # Check how many more rows are needed to reach 10,000 unique BDSPPatientID\n",
    "# current_unique_count = cleaned_sampled_df['BDSPPatientID'].nunique()\n",
    "# additional_rows_needed = 10000 - current_unique_count\n",
    "\n",
    "# if additional_rows_needed > 0:\n",
    "#     # Identify non-sampled patients\n",
    "#     remaining_patients = complete_df_initial[~complete_df_initial['BDSPPatientID'].isin(cleaned_sampled_df['BDSPPatientID'])]\n",
    "    \n",
    "#     # Sample additional rows to reach the desired count\n",
    "#     additional_df = remaining_patients.sample(n=additional_rows_needed, random_state=103)\n",
    "    \n",
    "#     # Combine cleaned sample with additional rows\n",
    "#     final_df = pd.concat([cleaned_sampled_df, additional_df], ignore_index=True)\n",
    "# else:\n",
    "#     final_df = cleaned_sampled_df\n",
    "\n",
    "# # Ensure final_df contains 10,000 unique BDSPPatientID values\n",
    "# final_df = final_df.drop_duplicates(subset='BDSPPatientID', keep='first')\n",
    "# final_df = final_df.reset_index(drop=True)\n",
    "\n",
    "# # Check for and remove any additional duplicates, ensuring exactly 10,000 rows\n",
    "# while final_df['BDSPPatientID'].nunique() < 10000:\n",
    "#     current_count = final_df['BDSPPatientID'].nunique()\n",
    "#     additional_needed = 10000 - current_count\n",
    "    \n",
    "#     remaining_patients = complete_df_initial[~complete_df_initial['BDSPPatientID'].isin(final_df['BDSPPatientID'])]\n",
    "#     additional_df = remaining_patients.sample(n=additional_needed, random_state=104)\n",
    "    \n",
    "#     final_df = pd.concat([final_df, additional_df], ignore_index=True)\n",
    "#     final_df = final_df.drop_duplicates(subset='BDSPPatientID', keep='first').reset_index(drop=True)\n",
    "\n",
    "# # Save the final DataFrame to a new CSV file\n",
    "# final_df.to_csv(\"/home/gregory178/Desktop/NAX project/NAX_SDH/10000_rows_BI.csv\", index=False)\n",
    "\n",
    "# print(\"Final DataFrame with 10,000 unique BDSPPatientID rows saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
